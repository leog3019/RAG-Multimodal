{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ce2aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_dataset\\val2017.zip ya existe.\n",
      "Extrayendo coco_dataset\\val2017.zip...\n",
      "coco_dataset\\annotations_trainval2017.zip ya existe.\n",
      "Extrayendo coco_dataset\\annotations_trainval2017.zip...\n",
      "Primeras filas del dataset:\n",
      "                              image_path  \\\n",
      "0  coco_dataset\\val2017\\000000179765.jpg   \n",
      "1  coco_dataset\\val2017\\000000179765.jpg   \n",
      "2  coco_dataset\\val2017\\000000190236.jpg   \n",
      "3  coco_dataset\\val2017\\000000331352.jpg   \n",
      "4  coco_dataset\\val2017\\000000517069.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  A black Honda motorcycle parked in front of a ...  \n",
      "1      A Honda motorcycle parked in a grass driveway  \n",
      "2  An office cubicle with four different types of...  \n",
      "3          A small closed toilet in a cramped space.  \n",
      "4     Two women waiting at a bench next to a street.  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Crear carpeta base\n",
    "DATASET_DIR = \"coco_dataset\"\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "# URLs a descargar\n",
    "urls = {\n",
    "    \"val_images\": \"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "    \"annotations\": \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "}\n",
    "\n",
    "# Descargar y extraer archivos\n",
    "for name, url in urls.items():\n",
    "    filename = os.path.join(DATASET_DIR, url.split(\"/\")[-1])\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Descargando {name}...\")\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "    else:\n",
    "        print(f\"{filename} ya existe.\")\n",
    "\n",
    "    print(f\"Extrayendo {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATASET_DIR)\n",
    "\n",
    "# Leer captions del archivo JSON\n",
    "with open(os.path.join(DATASET_DIR, \"annotations\", \"captions_val2017.json\"), \"r\") as f:\n",
    "    captions_data = json.load(f)\n",
    "\n",
    "# Mapear IDs de imagen a nombres de archivo\n",
    "id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in captions_data[\"images\"]}\n",
    "\n",
    "# Construir un DataFrame con imágenes y captions\n",
    "records = []\n",
    "for ann in captions_data[\"annotations\"]:\n",
    "    image_id = ann[\"image_id\"]\n",
    "    caption = ann[\"caption\"]\n",
    "    filename = id_to_filename[image_id]\n",
    "    full_path = os.path.join(DATASET_DIR, \"val2017\", filename)\n",
    "    records.append({\"image_path\": full_path, \"caption\": caption})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Opcional: Guardar CSV\n",
    "df.to_csv(\"coco_val2017_captions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029908e",
   "metadata": {},
   "source": [
    "Preprocesamiento de texto e imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38663027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Leo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image_path  \\\n",
      "0  coco_dataset\\val2017\\000000179765.jpg   \n",
      "1  coco_dataset\\val2017\\000000179765.jpg   \n",
      "2  coco_dataset\\val2017\\000000190236.jpg   \n",
      "3  coco_dataset\\val2017\\000000331352.jpg   \n",
      "4  coco_dataset\\val2017\\000000517069.jpg   \n",
      "\n",
      "                                             caption  \\\n",
      "0  A black Honda motorcycle parked in front of a ...   \n",
      "1      A Honda motorcycle parked in a grass driveway   \n",
      "2  An office cubicle with four different types of...   \n",
      "3          A small closed toilet in a cramped space.   \n",
      "4     Two women waiting at a bench next to a street.   \n",
      "\n",
      "                               processed_caption  \n",
      "0     black honda motorcycle parked front garage  \n",
      "1         honda motorcycle parked grass driveway  \n",
      "2  office cubicle four different types computers  \n",
      "3              small closed toilet cramped space  \n",
      "4            two women waiting bench next street  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Cargar el CSV\n",
    "df = pd.read_csv(\"coco_val2017_captions.csv\")\n",
    "\n",
    "# Función de limpieza\n",
    "def preprocess_caption(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # eliminar puntuación\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Agregar columna limpia\n",
    "df[\"processed_caption\"] = df[\"caption\"].apply(preprocess_caption)\n",
    "\n",
    "# Ver primeras filas\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936ac75",
   "metadata": {},
   "source": [
    "Procesamiento y limpieza de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56873b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25014/25014 [02:54<00:00, 143.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Imágenes procesadas y guardadas individualmente!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Leer CSV\n",
    "df = pd.read_csv(\"coco_val2017_captions.csv\")\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "# Directorio de salida\n",
    "os.makedirs(\"processed_numpy\", exist_ok=True)\n",
    "\n",
    "# Procesar una a una y guardar en archivos individuales (para evitar sobrecarga de RAM)\n",
    "valid_rows = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    img_path = row[\"image_path\"]\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_resized = img.resize(TARGET_SIZE)\n",
    "        img_array = np.asarray(img_resized) / 255.0\n",
    "\n",
    "        if img_array.shape != (224, 224, 3):\n",
    "            raise ValueError(\"Forma inesperada\")\n",
    "\n",
    "        # Guardar como .npy individual\n",
    "        filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        np.save(f\"processed_numpy/{filename}.npy\", img_array)\n",
    "\n",
    "        valid_rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error con {img_path}: {e}\")\n",
    "\n",
    "# Guardar CSV con solo las filas válidas\n",
    "df_valid = pd.DataFrame(valid_rows)\n",
    "df_valid.to_csv(\"captions_valid.csv\", index=False)\n",
    "\n",
    "print(\"¡Imágenes procesadas y guardadas individualmente!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bb36b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "caption",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "eb9c209f-28ad-42d3-83e4-d0c540c724d3",
       "rows": [
        [
         "0",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A black Honda motorcycle parked in front of a garage."
        ],
        [
         "1",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A Honda motorcycle parked in a grass driveway"
        ],
        [
         "2",
         "coco_dataset\\val2017\\000000190236.jpg",
         "An office cubicle with four different types of computers."
        ],
        [
         "3",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A small closed toilet in a cramped space."
        ],
        [
         "4",
         "coco_dataset\\val2017\\000000517069.jpg",
         "Two women waiting at a bench next to a street."
        ],
        [
         "5",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A black Honda motorcycle with a dark burgundy seat."
        ],
        [
         "6",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A tan toilet and sink combination in a small room."
        ],
        [
         "7",
         "coco_dataset\\val2017\\000000190236.jpg",
         "The home office space seems to be very cluttered."
        ],
        [
         "8",
         "coco_dataset\\val2017\\000000182417.jpg",
         "A beautiful dessert waiting to be shared by two people"
        ],
        [
         "9",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench and a woman standing waiting for the bus."
        ],
        [
         "10",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench in the middle of the city"
        ],
        [
         "11",
         "coco_dataset\\val2017\\000000331352.jpg",
         "This is an advanced toilet with a sink and control panel."
        ],
        [
         "12",
         "coco_dataset\\val2017\\000000046378.jpg",
         "A cat eating a bird it has caught."
        ],
        [
         "13",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A close-up picture of a toilet with a fountain."
        ],
        [
         "14",
         "coco_dataset\\val2017\\000000093437.jpg",
         "A shot of an elderly man inside a kitchen."
        ],
        [
         "15",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat in between two cars in a parking lot."
        ],
        [
         "16",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench and a woman standing behind the bench at a bus stop"
        ],
        [
         "17",
         "coco_dataset\\val2017\\000000472678.jpg",
         "An office cubicle with multiple computers in it"
        ],
        [
         "18",
         "coco_dataset\\val2017\\000000093437.jpg",
         "An old man is wearing an odd hat"
        ],
        [
         "19",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A parade of motorcycles is going through a group of tall trees."
        ],
        [
         "20",
         "coco_dataset\\val2017\\000000223747.jpg",
         "a man sleeping with his cat next to him"
        ],
        [
         "21",
         "coco_dataset\\val2017\\000000109976.jpg",
         "An all white kitchen with an electric stovetop. "
        ],
        [
         "22",
         "coco_dataset\\val2017\\000000190236.jpg",
         "an office with desk computer and chair and laptop."
        ],
        [
         "23",
         "coco_dataset\\val2017\\000000012667.jpg",
         "The telephone has a banana where the receiver should be."
        ],
        [
         "24",
         "coco_dataset\\val2017\\000000331352.jpg",
         "Off white toilet with a faucet and controls. "
        ],
        [
         "25",
         "coco_dataset\\val2017\\000000109976.jpg",
         "A white stove sits between two small counter tops."
        ],
        [
         "26",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman and another woman waiting at a stop."
        ],
        [
         "27",
         "coco_dataset\\val2017\\000000190236.jpg",
         "Office setting with a lot of computer screens."
        ],
        [
         "28",
         "coco_dataset\\val2017\\000000109976.jpg",
         "Close up of a white kitchen setup with a coffee maker on counter."
        ],
        [
         "29",
         "coco_dataset\\val2017\\000000190236.jpg",
         "A desk and chair in an office cubicle."
        ],
        [
         "30",
         "coco_dataset\\val2017\\000000109976.jpg",
         "A white stove and cabinet inside a kitchen."
        ],
        [
         "31",
         "coco_dataset\\val2017\\000000182417.jpg",
         "There is a piece of cake on a plate with decorations on it."
        ],
        [
         "32",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat stands between two parked cars on a grassy sidewalk. "
        ],
        [
         "33",
         "coco_dataset\\val2017\\000000182417.jpg",
         "Creamy cheesecake dessert with whip cream and caramel."
        ],
        [
         "34",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A group of motorcyclists drive down a tree lined street."
        ],
        [
         "35",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat at attention between two parked cars."
        ],
        [
         "36",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog sitting between its masters feet on a footstool watching tv\n"
        ],
        [
         "37",
         "coco_dataset\\val2017\\000000223747.jpg",
         "A young man and his cute cat enjoy a nap together."
        ],
        [
         "38",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog between the feet of a person looking at a TV."
        ],
        [
         "39",
         "coco_dataset\\val2017\\000000093437.jpg",
         "An older man is wearing a funny hat in his dining room."
        ],
        [
         "40",
         "coco_dataset\\val2017\\000000534605.jpg",
         "Man in motorcycle leathers standing in front of a group of bikes"
        ],
        [
         "41",
         "coco_dataset\\val2017\\000000534605.jpg",
         "Bikers, dressed in their gear, standing near their motorcycles."
        ],
        [
         "42",
         "coco_dataset\\val2017\\000000223747.jpg",
         "A man is sleeping with his head on a pillow."
        ],
        [
         "43",
         "coco_dataset\\val2017\\000000012667.jpg",
         "A banana replacing the phone on an answering machine"
        ],
        [
         "44",
         "coco_dataset\\val2017\\000000179765.jpg",
         "Ma motorcycle parked on the gravel in front of a garage"
        ],
        [
         "45",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog and a person are watching television together."
        ],
        [
         "46",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A motorcycle with its brake extended standing outside"
        ],
        [
         "47",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A group of motorcycles down a long street filled with trees on either side."
        ],
        [
         "48",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A person is sitting with their dog watching tv."
        ],
        [
         "49",
         "coco_dataset\\val2017\\000000472678.jpg",
         "An office desk with two flat panel monitors."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 25014
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coco_dataset\\val2017\\000000179765.jpg</td>\n",
       "      <td>A black Honda motorcycle parked in front of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coco_dataset\\val2017\\000000179765.jpg</td>\n",
       "      <td>A Honda motorcycle parked in a grass driveway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coco_dataset\\val2017\\000000190236.jpg</td>\n",
       "      <td>An office cubicle with four different types of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coco_dataset\\val2017\\000000331352.jpg</td>\n",
       "      <td>A small closed toilet in a cramped space.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coco_dataset\\val2017\\000000517069.jpg</td>\n",
       "      <td>Two women waiting at a bench next to a street.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25009</th>\n",
       "      <td>coco_dataset\\val2017\\000000009590.jpg</td>\n",
       "      <td>A group of men sipping drinks and talking at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>coco_dataset\\val2017\\000000084664.jpg</td>\n",
       "      <td>A plate of food with some eggs, potatoes, brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>coco_dataset\\val2017\\000000331569.jpg</td>\n",
       "      <td>The strawberries was sitting beside the tall g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>coco_dataset\\val2017\\000000231237.jpg</td>\n",
       "      <td>A bunch of small red flowers in a barnacle enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25013</th>\n",
       "      <td>coco_dataset\\val2017\\000000386134.jpg</td>\n",
       "      <td>Food is in a styrofoam take out container.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25014 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path  \\\n",
       "0      coco_dataset\\val2017\\000000179765.jpg   \n",
       "1      coco_dataset\\val2017\\000000179765.jpg   \n",
       "2      coco_dataset\\val2017\\000000190236.jpg   \n",
       "3      coco_dataset\\val2017\\000000331352.jpg   \n",
       "4      coco_dataset\\val2017\\000000517069.jpg   \n",
       "...                                      ...   \n",
       "25009  coco_dataset\\val2017\\000000009590.jpg   \n",
       "25010  coco_dataset\\val2017\\000000084664.jpg   \n",
       "25011  coco_dataset\\val2017\\000000331569.jpg   \n",
       "25012  coco_dataset\\val2017\\000000231237.jpg   \n",
       "25013  coco_dataset\\val2017\\000000386134.jpg   \n",
       "\n",
       "                                                 caption  \n",
       "0      A black Honda motorcycle parked in front of a ...  \n",
       "1          A Honda motorcycle parked in a grass driveway  \n",
       "2      An office cubicle with four different types of...  \n",
       "3              A small closed toilet in a cramped space.  \n",
       "4         Two women waiting at a bench next to a street.  \n",
       "...                                                  ...  \n",
       "25009  A group of men sipping drinks and talking at a...  \n",
       "25010  A plate of food with some eggs, potatoes, brea...  \n",
       "25011  The strawberries was sitting beside the tall g...  \n",
       "25012  A bunch of small red flowers in a barnacle enc...  \n",
       "25013         Food is in a styrofoam take out container.  \n",
       "\n",
       "[25014 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c8e12",
   "metadata": {},
   "source": [
    "Procesamiento y limpieza del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413e5f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Leo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image_path  \\\n",
      "0  coco_dataset\\val2017\\000000179765.jpg   \n",
      "1  coco_dataset\\val2017\\000000179765.jpg   \n",
      "2  coco_dataset\\val2017\\000000190236.jpg   \n",
      "3  coco_dataset\\val2017\\000000331352.jpg   \n",
      "4  coco_dataset\\val2017\\000000517069.jpg   \n",
      "\n",
      "                                             caption  \\\n",
      "0  A black Honda motorcycle parked in front of a ...   \n",
      "1      A Honda motorcycle parked in a grass driveway   \n",
      "2  An office cubicle with four different types of...   \n",
      "3          A small closed toilet in a cramped space.   \n",
      "4     Two women waiting at a bench next to a street.   \n",
      "\n",
      "                               processed_caption  \n",
      "0     black honda motorcycle parked front garage  \n",
      "1         honda motorcycle parked grass driveway  \n",
      "2  office cubicle four different types computers  \n",
      "3              small closed toilet cramped space  \n",
      "4            two women waiting bench next street  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Cargar el CSV\n",
    "df = pd.read_csv(\"captions_valid.csv\")\n",
    "\n",
    "# Función de limpieza\n",
    "def preprocess_caption(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # eliminar puntuación\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Agregar columna limpia\n",
    "df[\"processed_caption\"] = df[\"caption\"].apply(preprocess_caption)\n",
    "\n",
    "# Ver primeras filas\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b385ac98",
   "metadata": {},
   "source": [
    "Transformación de texto e imágenes a embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995b5a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "caption",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "processed_caption",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "069cd318-25f8-44e9-89b0-2c771b90036e",
       "rows": [
        [
         "0",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A black Honda motorcycle parked in front of a garage.",
         "black honda motorcycle parked front garage"
        ],
        [
         "1",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A Honda motorcycle parked in a grass driveway",
         "honda motorcycle parked grass driveway"
        ],
        [
         "2",
         "coco_dataset\\val2017\\000000190236.jpg",
         "An office cubicle with four different types of computers.",
         "office cubicle four different types computers"
        ],
        [
         "3",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A small closed toilet in a cramped space.",
         "small closed toilet cramped space"
        ],
        [
         "4",
         "coco_dataset\\val2017\\000000517069.jpg",
         "Two women waiting at a bench next to a street.",
         "two women waiting bench next street"
        ],
        [
         "5",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A black Honda motorcycle with a dark burgundy seat.",
         "black honda motorcycle dark burgundy seat"
        ],
        [
         "6",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A tan toilet and sink combination in a small room.",
         "tan toilet sink combination small room"
        ],
        [
         "7",
         "coco_dataset\\val2017\\000000190236.jpg",
         "The home office space seems to be very cluttered.",
         "home office space seems cluttered"
        ],
        [
         "8",
         "coco_dataset\\val2017\\000000182417.jpg",
         "A beautiful dessert waiting to be shared by two people",
         "beautiful dessert waiting shared two people"
        ],
        [
         "9",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench and a woman standing waiting for the bus.",
         "woman sitting bench woman standing waiting bus"
        ],
        [
         "10",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench in the middle of the city",
         "woman sitting bench middle city"
        ],
        [
         "11",
         "coco_dataset\\val2017\\000000331352.jpg",
         "This is an advanced toilet with a sink and control panel.",
         "advanced toilet sink control panel"
        ],
        [
         "12",
         "coco_dataset\\val2017\\000000046378.jpg",
         "A cat eating a bird it has caught.",
         "cat eating bird caught"
        ],
        [
         "13",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A close-up picture of a toilet with a fountain.",
         "closeup picture toilet fountain"
        ],
        [
         "14",
         "coco_dataset\\val2017\\000000093437.jpg",
         "A shot of an elderly man inside a kitchen.",
         "shot elderly man inside kitchen"
        ],
        [
         "15",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat in between two cars in a parking lot.",
         "cat two cars parking lot"
        ],
        [
         "16",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench and a woman standing behind the bench at a bus stop",
         "woman sitting bench woman standing behind bench bus stop"
        ],
        [
         "17",
         "coco_dataset\\val2017\\000000472678.jpg",
         "An office cubicle with multiple computers in it",
         "office cubicle multiple computers"
        ],
        [
         "18",
         "coco_dataset\\val2017\\000000093437.jpg",
         "An old man is wearing an odd hat",
         "old man wearing odd hat"
        ],
        [
         "19",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A parade of motorcycles is going through a group of tall trees.",
         "parade motorcycles going group tall trees"
        ],
        [
         "20",
         "coco_dataset\\val2017\\000000223747.jpg",
         "a man sleeping with his cat next to him",
         "man sleeping cat next"
        ],
        [
         "21",
         "coco_dataset\\val2017\\000000109976.jpg",
         "An all white kitchen with an electric stovetop. ",
         "white kitchen electric stovetop"
        ],
        [
         "22",
         "coco_dataset\\val2017\\000000190236.jpg",
         "an office with desk computer and chair and laptop.",
         "office desk computer chair laptop"
        ],
        [
         "23",
         "coco_dataset\\val2017\\000000012667.jpg",
         "The telephone has a banana where the receiver should be.",
         "telephone banana receiver"
        ],
        [
         "24",
         "coco_dataset\\val2017\\000000331352.jpg",
         "Off white toilet with a faucet and controls. ",
         "white toilet faucet controls"
        ],
        [
         "25",
         "coco_dataset\\val2017\\000000109976.jpg",
         "A white stove sits between two small counter tops.",
         "white stove sits two small counter tops"
        ],
        [
         "26",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman and another woman waiting at a stop.",
         "woman another woman waiting stop"
        ],
        [
         "27",
         "coco_dataset\\val2017\\000000190236.jpg",
         "Office setting with a lot of computer screens.",
         "office setting lot computer screens"
        ],
        [
         "28",
         "coco_dataset\\val2017\\000000109976.jpg",
         "Close up of a white kitchen setup with a coffee maker on counter.",
         "close white kitchen setup coffee maker counter"
        ],
        [
         "29",
         "coco_dataset\\val2017\\000000190236.jpg",
         "A desk and chair in an office cubicle.",
         "desk chair office cubicle"
        ],
        [
         "30",
         "coco_dataset\\val2017\\000000109976.jpg",
         "A white stove and cabinet inside a kitchen.",
         "white stove cabinet inside kitchen"
        ],
        [
         "31",
         "coco_dataset\\val2017\\000000182417.jpg",
         "There is a piece of cake on a plate with decorations on it.",
         "piece cake plate decorations"
        ],
        [
         "32",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat stands between two parked cars on a grassy sidewalk. ",
         "cat stands two parked cars grassy sidewalk"
        ],
        [
         "33",
         "coco_dataset\\val2017\\000000182417.jpg",
         "Creamy cheesecake dessert with whip cream and caramel.",
         "creamy cheesecake dessert whip cream caramel"
        ],
        [
         "34",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A group of motorcyclists drive down a tree lined street.",
         "group motorcyclists drive tree lined street"
        ],
        [
         "35",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat at attention between two parked cars.",
         "cat attention two parked cars"
        ],
        [
         "36",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog sitting between its masters feet on a footstool watching tv\n",
         "dog sitting masters feet footstool watching tv"
        ],
        [
         "37",
         "coco_dataset\\val2017\\000000223747.jpg",
         "A young man and his cute cat enjoy a nap together.",
         "young man cute cat enjoy nap together"
        ],
        [
         "38",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog between the feet of a person looking at a TV.",
         "dog feet person looking tv"
        ],
        [
         "39",
         "coco_dataset\\val2017\\000000093437.jpg",
         "An older man is wearing a funny hat in his dining room.",
         "older man wearing funny hat dining room"
        ],
        [
         "40",
         "coco_dataset\\val2017\\000000534605.jpg",
         "Man in motorcycle leathers standing in front of a group of bikes",
         "man motorcycle leathers standing front group bikes"
        ],
        [
         "41",
         "coco_dataset\\val2017\\000000534605.jpg",
         "Bikers, dressed in their gear, standing near their motorcycles.",
         "bikers dressed gear standing near motorcycles"
        ],
        [
         "42",
         "coco_dataset\\val2017\\000000223747.jpg",
         "A man is sleeping with his head on a pillow.",
         "man sleeping head pillow"
        ],
        [
         "43",
         "coco_dataset\\val2017\\000000012667.jpg",
         "A banana replacing the phone on an answering machine",
         "banana replacing phone answering machine"
        ],
        [
         "44",
         "coco_dataset\\val2017\\000000179765.jpg",
         "Ma motorcycle parked on the gravel in front of a garage",
         "motorcycle parked gravel front garage"
        ],
        [
         "45",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog and a person are watching television together.",
         "dog person watching television together"
        ],
        [
         "46",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A motorcycle with its brake extended standing outside",
         "motorcycle brake extended standing outside"
        ],
        [
         "47",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A group of motorcycles down a long street filled with trees on either side.",
         "group motorcycles long street filled trees either side"
        ],
        [
         "48",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A person is sitting with their dog watching tv.",
         "person sitting dog watching tv"
        ],
        [
         "49",
         "coco_dataset\\val2017\\000000472678.jpg",
         "An office desk with two flat panel monitors.",
         "office desk two flat panel monitors"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 25014
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>processed_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coco_dataset\\val2017\\000000179765.jpg</td>\n",
       "      <td>A black Honda motorcycle parked in front of a ...</td>\n",
       "      <td>black honda motorcycle parked front garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coco_dataset\\val2017\\000000179765.jpg</td>\n",
       "      <td>A Honda motorcycle parked in a grass driveway</td>\n",
       "      <td>honda motorcycle parked grass driveway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coco_dataset\\val2017\\000000190236.jpg</td>\n",
       "      <td>An office cubicle with four different types of...</td>\n",
       "      <td>office cubicle four different types computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coco_dataset\\val2017\\000000331352.jpg</td>\n",
       "      <td>A small closed toilet in a cramped space.</td>\n",
       "      <td>small closed toilet cramped space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coco_dataset\\val2017\\000000517069.jpg</td>\n",
       "      <td>Two women waiting at a bench next to a street.</td>\n",
       "      <td>two women waiting bench next street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25009</th>\n",
       "      <td>coco_dataset\\val2017\\000000009590.jpg</td>\n",
       "      <td>A group of men sipping drinks and talking at a...</td>\n",
       "      <td>group men sipping drinks talking table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>coco_dataset\\val2017\\000000084664.jpg</td>\n",
       "      <td>A plate of food with some eggs, potatoes, brea...</td>\n",
       "      <td>plate food eggs potatoes bread items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>coco_dataset\\val2017\\000000331569.jpg</td>\n",
       "      <td>The strawberries was sitting beside the tall g...</td>\n",
       "      <td>strawberries sitting beside tall glass milkshake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>coco_dataset\\val2017\\000000231237.jpg</td>\n",
       "      <td>A bunch of small red flowers in a barnacle enc...</td>\n",
       "      <td>bunch small red flowers barnacle encrusted cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25013</th>\n",
       "      <td>coco_dataset\\val2017\\000000386134.jpg</td>\n",
       "      <td>Food is in a styrofoam take out container.</td>\n",
       "      <td>food styrofoam take container</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path  \\\n",
       "0      coco_dataset\\val2017\\000000179765.jpg   \n",
       "1      coco_dataset\\val2017\\000000179765.jpg   \n",
       "2      coco_dataset\\val2017\\000000190236.jpg   \n",
       "3      coco_dataset\\val2017\\000000331352.jpg   \n",
       "4      coco_dataset\\val2017\\000000517069.jpg   \n",
       "...                                      ...   \n",
       "25009  coco_dataset\\val2017\\000000009590.jpg   \n",
       "25010  coco_dataset\\val2017\\000000084664.jpg   \n",
       "25011  coco_dataset\\val2017\\000000331569.jpg   \n",
       "25012  coco_dataset\\val2017\\000000231237.jpg   \n",
       "25013  coco_dataset\\val2017\\000000386134.jpg   \n",
       "\n",
       "                                                 caption  \\\n",
       "0      A black Honda motorcycle parked in front of a ...   \n",
       "1          A Honda motorcycle parked in a grass driveway   \n",
       "2      An office cubicle with four different types of...   \n",
       "3              A small closed toilet in a cramped space.   \n",
       "4         Two women waiting at a bench next to a street.   \n",
       "...                                                  ...   \n",
       "25009  A group of men sipping drinks and talking at a...   \n",
       "25010  A plate of food with some eggs, potatoes, brea...   \n",
       "25011  The strawberries was sitting beside the tall g...   \n",
       "25012  A bunch of small red flowers in a barnacle enc...   \n",
       "25013         Food is in a styrofoam take out container.   \n",
       "\n",
       "                                       processed_caption  \n",
       "0             black honda motorcycle parked front garage  \n",
       "1                 honda motorcycle parked grass driveway  \n",
       "2          office cubicle four different types computers  \n",
       "3                      small closed toilet cramped space  \n",
       "4                    two women waiting bench next street  \n",
       "...                                                  ...  \n",
       "25009             group men sipping drinks talking table  \n",
       "25010               plate food eggs potatoes bread items  \n",
       "25011   strawberries sitting beside tall glass milkshake  \n",
       "25012  bunch small red flowers barnacle encrusted cla...  \n",
       "25013                      food styrofoam take container  \n",
       "\n",
       "[25014 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b993c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\Documents\\IR25A\\SRI2025\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Procesando texto con CLIP: 100%|██████████| 25014/25014 [08:50<00:00, 47.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings de texto con CLIP generados:\n",
      "                                             caption  \\\n",
      "0  A black Honda motorcycle parked in front of a ...   \n",
      "1      A Honda motorcycle parked in a grass driveway   \n",
      "2  An office cubicle with four different types of...   \n",
      "3          A small closed toilet in a cramped space.   \n",
      "4     Two women waiting at a bench next to a street.   \n",
      "\n",
      "                               processed_caption         0         1  \\\n",
      "0     black honda motorcycle parked front garage  0.580966 -0.228733   \n",
      "1         honda motorcycle parked grass driveway  0.285237 -0.381514   \n",
      "2  office cubicle four different types computers -0.276178 -0.156697   \n",
      "3              small closed toilet cramped space -0.309372  0.300551   \n",
      "4            two women waiting bench next street -0.089082 -0.216656   \n",
      "\n",
      "          2         3         4         5         6         7  ...       502  \\\n",
      "0  0.353271  0.001215 -0.175542 -0.259786  0.076120  0.121080  ... -0.435310   \n",
      "1  0.259527 -0.176544 -0.390235  0.367454 -0.022089  0.010679  ... -0.039479   \n",
      "2  0.014707  0.021553 -0.239660  0.002820 -0.341837  0.336765  ... -0.029534   \n",
      "3  0.141421  0.392783 -0.080031  0.132160 -0.168922 -0.641874  ... -0.014108   \n",
      "4 -0.223601 -0.716167  0.012618 -0.150132  0.046965 -0.444322  ...  0.094293   \n",
      "\n",
      "        503       504       505       506       507       508       509  \\\n",
      "0  0.500887  0.617322  0.013184 -0.444917 -0.347568  0.198554  0.937915   \n",
      "1  0.181641  0.324994 -0.178735 -0.192340 -0.096065  0.074263  0.856009   \n",
      "2  0.165032  1.008730  0.021943 -0.069367  0.123085  0.404668  0.225444   \n",
      "3  0.067370  0.215456  0.086490 -0.267428 -0.311038  0.248305  0.267653   \n",
      "4 -0.015525  0.629062 -0.166032 -0.167049  0.138471 -0.010505  0.159878   \n",
      "\n",
      "        510       511  \n",
      "0 -0.030100  0.313767  \n",
      "1 -0.403411  0.575979  \n",
      "2 -0.055343 -0.282191  \n",
      "3 -0.166564 -0.234625  \n",
      "4 -0.178217 -0.264120  \n",
      "\n",
      "[5 rows x 514 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. Cargar modelo CLIP\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model.to(device)\n",
    "\n",
    "# 3. Generar embeddings de texto con CLIP\n",
    "clip_text_embeddings = []\n",
    "\n",
    "for text in tqdm(df[\"processed_caption\"].tolist(), desc=\"Procesando texto con CLIP\"):\n",
    "    try:\n",
    "        inputs = clip_processor(text=[text], return_tensors=\"pt\", padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = clip_model.get_text_features(**inputs)\n",
    "            embedding = outputs[0].cpu().numpy()\n",
    "        clip_text_embeddings.append(embedding)\n",
    "    except Exception as e:\n",
    "        print(f\"Error con texto: {text}: {e}\")\n",
    "        clip_text_embeddings.append(np.zeros(512))  # vector nulo si falla\n",
    "\n",
    "# 4. Convertir a DataFrame\n",
    "embedding_array = np.vstack(clip_text_embeddings)\n",
    "embedding_df = pd.DataFrame(embedding_array)\n",
    "\n",
    "# 5. Unir con columnas originales\n",
    "df_embed = pd.concat([df[[\"caption\", \"processed_caption\"]].reset_index(drop=True), embedding_df], axis=1)\n",
    "\n",
    "# 6. Guardar o mostrar\n",
    "df_embed.to_csv(\"text_embeddings_clip.csv\", index=False)\n",
    "print(\"Embeddings de texto con CLIP generados:\")\n",
    "print(df_embed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29f735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "caption",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "processed_caption",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9b678a43-8658-404b-9c53-e780b33035c2",
       "rows": [
        [
         "0",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A black Honda motorcycle parked in front of a garage.",
         "black honda motorcycle parked front garage"
        ],
        [
         "1",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A Honda motorcycle parked in a grass driveway",
         "honda motorcycle parked grass driveway"
        ],
        [
         "2",
         "coco_dataset\\val2017\\000000190236.jpg",
         "An office cubicle with four different types of computers.",
         "office cubicle four different types computers"
        ],
        [
         "3",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A small closed toilet in a cramped space.",
         "small closed toilet cramped space"
        ],
        [
         "4",
         "coco_dataset\\val2017\\000000517069.jpg",
         "Two women waiting at a bench next to a street.",
         "two women waiting bench next street"
        ],
        [
         "5",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A black Honda motorcycle with a dark burgundy seat.",
         "black honda motorcycle dark burgundy seat"
        ],
        [
         "6",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A tan toilet and sink combination in a small room.",
         "tan toilet sink combination small room"
        ],
        [
         "7",
         "coco_dataset\\val2017\\000000190236.jpg",
         "The home office space seems to be very cluttered.",
         "home office space seems cluttered"
        ],
        [
         "8",
         "coco_dataset\\val2017\\000000182417.jpg",
         "A beautiful dessert waiting to be shared by two people",
         "beautiful dessert waiting shared two people"
        ],
        [
         "9",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench and a woman standing waiting for the bus.",
         "woman sitting bench woman standing waiting bus"
        ],
        [
         "10",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench in the middle of the city",
         "woman sitting bench middle city"
        ],
        [
         "11",
         "coco_dataset\\val2017\\000000331352.jpg",
         "This is an advanced toilet with a sink and control panel.",
         "advanced toilet sink control panel"
        ],
        [
         "12",
         "coco_dataset\\val2017\\000000046378.jpg",
         "A cat eating a bird it has caught.",
         "cat eating bird caught"
        ],
        [
         "13",
         "coco_dataset\\val2017\\000000331352.jpg",
         "A close-up picture of a toilet with a fountain.",
         "closeup picture toilet fountain"
        ],
        [
         "14",
         "coco_dataset\\val2017\\000000093437.jpg",
         "A shot of an elderly man inside a kitchen.",
         "shot elderly man inside kitchen"
        ],
        [
         "15",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat in between two cars in a parking lot.",
         "cat two cars parking lot"
        ],
        [
         "16",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman sitting on a bench and a woman standing behind the bench at a bus stop",
         "woman sitting bench woman standing behind bench bus stop"
        ],
        [
         "17",
         "coco_dataset\\val2017\\000000472678.jpg",
         "An office cubicle with multiple computers in it",
         "office cubicle multiple computers"
        ],
        [
         "18",
         "coco_dataset\\val2017\\000000093437.jpg",
         "An old man is wearing an odd hat",
         "old man wearing odd hat"
        ],
        [
         "19",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A parade of motorcycles is going through a group of tall trees.",
         "parade motorcycles going group tall trees"
        ],
        [
         "20",
         "coco_dataset\\val2017\\000000223747.jpg",
         "a man sleeping with his cat next to him",
         "man sleeping cat next"
        ],
        [
         "21",
         "coco_dataset\\val2017\\000000109976.jpg",
         "An all white kitchen with an electric stovetop. ",
         "white kitchen electric stovetop"
        ],
        [
         "22",
         "coco_dataset\\val2017\\000000190236.jpg",
         "an office with desk computer and chair and laptop.",
         "office desk computer chair laptop"
        ],
        [
         "23",
         "coco_dataset\\val2017\\000000012667.jpg",
         "The telephone has a banana where the receiver should be.",
         "telephone banana receiver"
        ],
        [
         "24",
         "coco_dataset\\val2017\\000000331352.jpg",
         "Off white toilet with a faucet and controls. ",
         "white toilet faucet controls"
        ],
        [
         "25",
         "coco_dataset\\val2017\\000000109976.jpg",
         "A white stove sits between two small counter tops.",
         "white stove sits two small counter tops"
        ],
        [
         "26",
         "coco_dataset\\val2017\\000000517069.jpg",
         "A woman and another woman waiting at a stop.",
         "woman another woman waiting stop"
        ],
        [
         "27",
         "coco_dataset\\val2017\\000000190236.jpg",
         "Office setting with a lot of computer screens.",
         "office setting lot computer screens"
        ],
        [
         "28",
         "coco_dataset\\val2017\\000000109976.jpg",
         "Close up of a white kitchen setup with a coffee maker on counter.",
         "close white kitchen setup coffee maker counter"
        ],
        [
         "29",
         "coco_dataset\\val2017\\000000190236.jpg",
         "A desk and chair in an office cubicle.",
         "desk chair office cubicle"
        ],
        [
         "30",
         "coco_dataset\\val2017\\000000109976.jpg",
         "A white stove and cabinet inside a kitchen.",
         "white stove cabinet inside kitchen"
        ],
        [
         "31",
         "coco_dataset\\val2017\\000000182417.jpg",
         "There is a piece of cake on a plate with decorations on it.",
         "piece cake plate decorations"
        ],
        [
         "32",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat stands between two parked cars on a grassy sidewalk. ",
         "cat stands two parked cars grassy sidewalk"
        ],
        [
         "33",
         "coco_dataset\\val2017\\000000182417.jpg",
         "Creamy cheesecake dessert with whip cream and caramel.",
         "creamy cheesecake dessert whip cream caramel"
        ],
        [
         "34",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A group of motorcyclists drive down a tree lined street.",
         "group motorcyclists drive tree lined street"
        ],
        [
         "35",
         "coco_dataset\\val2017\\000000172330.jpg",
         "A cat at attention between two parked cars.",
         "cat attention two parked cars"
        ],
        [
         "36",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog sitting between its masters feet on a footstool watching tv\n",
         "dog sitting masters feet footstool watching tv"
        ],
        [
         "37",
         "coco_dataset\\val2017\\000000223747.jpg",
         "A young man and his cute cat enjoy a nap together.",
         "young man cute cat enjoy nap together"
        ],
        [
         "38",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog between the feet of a person looking at a TV.",
         "dog feet person looking tv"
        ],
        [
         "39",
         "coco_dataset\\val2017\\000000093437.jpg",
         "An older man is wearing a funny hat in his dining room.",
         "older man wearing funny hat dining room"
        ],
        [
         "40",
         "coco_dataset\\val2017\\000000534605.jpg",
         "Man in motorcycle leathers standing in front of a group of bikes",
         "man motorcycle leathers standing front group bikes"
        ],
        [
         "41",
         "coco_dataset\\val2017\\000000534605.jpg",
         "Bikers, dressed in their gear, standing near their motorcycles.",
         "bikers dressed gear standing near motorcycles"
        ],
        [
         "42",
         "coco_dataset\\val2017\\000000223747.jpg",
         "A man is sleeping with his head on a pillow.",
         "man sleeping head pillow"
        ],
        [
         "43",
         "coco_dataset\\val2017\\000000012667.jpg",
         "A banana replacing the phone on an answering machine",
         "banana replacing phone answering machine"
        ],
        [
         "44",
         "coco_dataset\\val2017\\000000179765.jpg",
         "Ma motorcycle parked on the gravel in front of a garage",
         "motorcycle parked gravel front garage"
        ],
        [
         "45",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A dog and a person are watching television together.",
         "dog person watching television together"
        ],
        [
         "46",
         "coco_dataset\\val2017\\000000179765.jpg",
         "A motorcycle with its brake extended standing outside",
         "motorcycle brake extended standing outside"
        ],
        [
         "47",
         "coco_dataset\\val2017\\000000314251.jpg",
         "A group of motorcycles down a long street filled with trees on either side.",
         "group motorcycles long street filled trees either side"
        ],
        [
         "48",
         "coco_dataset\\val2017\\000000482917.jpg",
         "A person is sitting with their dog watching tv.",
         "person sitting dog watching tv"
        ],
        [
         "49",
         "coco_dataset\\val2017\\000000472678.jpg",
         "An office desk with two flat panel monitors.",
         "office desk two flat panel monitors"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 25014
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>processed_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coco_dataset\\val2017\\000000179765.jpg</td>\n",
       "      <td>A black Honda motorcycle parked in front of a ...</td>\n",
       "      <td>black honda motorcycle parked front garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coco_dataset\\val2017\\000000179765.jpg</td>\n",
       "      <td>A Honda motorcycle parked in a grass driveway</td>\n",
       "      <td>honda motorcycle parked grass driveway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coco_dataset\\val2017\\000000190236.jpg</td>\n",
       "      <td>An office cubicle with four different types of...</td>\n",
       "      <td>office cubicle four different types computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coco_dataset\\val2017\\000000331352.jpg</td>\n",
       "      <td>A small closed toilet in a cramped space.</td>\n",
       "      <td>small closed toilet cramped space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coco_dataset\\val2017\\000000517069.jpg</td>\n",
       "      <td>Two women waiting at a bench next to a street.</td>\n",
       "      <td>two women waiting bench next street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25009</th>\n",
       "      <td>coco_dataset\\val2017\\000000009590.jpg</td>\n",
       "      <td>A group of men sipping drinks and talking at a...</td>\n",
       "      <td>group men sipping drinks talking table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>coco_dataset\\val2017\\000000084664.jpg</td>\n",
       "      <td>A plate of food with some eggs, potatoes, brea...</td>\n",
       "      <td>plate food eggs potatoes bread items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>coco_dataset\\val2017\\000000331569.jpg</td>\n",
       "      <td>The strawberries was sitting beside the tall g...</td>\n",
       "      <td>strawberries sitting beside tall glass milkshake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>coco_dataset\\val2017\\000000231237.jpg</td>\n",
       "      <td>A bunch of small red flowers in a barnacle enc...</td>\n",
       "      <td>bunch small red flowers barnacle encrusted cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25013</th>\n",
       "      <td>coco_dataset\\val2017\\000000386134.jpg</td>\n",
       "      <td>Food is in a styrofoam take out container.</td>\n",
       "      <td>food styrofoam take container</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path  \\\n",
       "0      coco_dataset\\val2017\\000000179765.jpg   \n",
       "1      coco_dataset\\val2017\\000000179765.jpg   \n",
       "2      coco_dataset\\val2017\\000000190236.jpg   \n",
       "3      coco_dataset\\val2017\\000000331352.jpg   \n",
       "4      coco_dataset\\val2017\\000000517069.jpg   \n",
       "...                                      ...   \n",
       "25009  coco_dataset\\val2017\\000000009590.jpg   \n",
       "25010  coco_dataset\\val2017\\000000084664.jpg   \n",
       "25011  coco_dataset\\val2017\\000000331569.jpg   \n",
       "25012  coco_dataset\\val2017\\000000231237.jpg   \n",
       "25013  coco_dataset\\val2017\\000000386134.jpg   \n",
       "\n",
       "                                                 caption  \\\n",
       "0      A black Honda motorcycle parked in front of a ...   \n",
       "1          A Honda motorcycle parked in a grass driveway   \n",
       "2      An office cubicle with four different types of...   \n",
       "3              A small closed toilet in a cramped space.   \n",
       "4         Two women waiting at a bench next to a street.   \n",
       "...                                                  ...   \n",
       "25009  A group of men sipping drinks and talking at a...   \n",
       "25010  A plate of food with some eggs, potatoes, brea...   \n",
       "25011  The strawberries was sitting beside the tall g...   \n",
       "25012  A bunch of small red flowers in a barnacle enc...   \n",
       "25013         Food is in a styrofoam take out container.   \n",
       "\n",
       "                                       processed_caption  \n",
       "0             black honda motorcycle parked front garage  \n",
       "1                 honda motorcycle parked grass driveway  \n",
       "2          office cubicle four different types computers  \n",
       "3                      small closed toilet cramped space  \n",
       "4                    two women waiting bench next street  \n",
       "...                                                  ...  \n",
       "25009             group men sipping drinks talking table  \n",
       "25010               plate food eggs potatoes bread items  \n",
       "25011   strawberries sitting beside tall glass milkshake  \n",
       "25012  bunch small red flowers barnacle encrusted cla...  \n",
       "25013                      food styrofoam take container  \n",
       "\n",
       "[25014 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e575aaa",
   "metadata": {},
   "source": [
    "Embedings imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658d3570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25014/25014 [30:09<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Embeddings generados y guardados en image_embeddings_clip.csv!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# 1. Cargar modelo CLIP localmente\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# 2. Cargar CSV de imágenes válidas\n",
    "df = pd.read_csv(\"captions_valid.csv\")\n",
    "\n",
    "# 3. Inicializar listas de salida\n",
    "image_embeddings = []\n",
    "valid_paths = []\n",
    "captions = []\n",
    "\n",
    "# 4. Procesar TODAS las imágenes\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    original_path = row[\"image_path\"]\n",
    "    caption = row[\"caption\"]\n",
    "    filename = os.path.splitext(os.path.basename(original_path))[0]\n",
    "    npy_path = os.path.join(\"processed_numpy\", f\"{filename}.npy\")\n",
    "\n",
    "    try:\n",
    "        # Leer la imagen desde el .npy y reconstruir como imagen PIL\n",
    "        img_array = np.load(npy_path)\n",
    "        img_array = (img_array * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(img_array).convert(\"RGB\")\n",
    "\n",
    "        # Preprocesamiento para CLIP\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Obtener embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model.get_image_features(**inputs)\n",
    "            embedding = outputs[0].cpu().numpy()  # Vector de 512 dimensiones\n",
    "\n",
    "        image_embeddings.append(embedding)\n",
    "        valid_paths.append(original_path)\n",
    "        captions.append(caption)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error con {npy_path}: {e}\")\n",
    "\n",
    "# 5. Guardar resultados\n",
    "embedding_df = pd.DataFrame(image_embeddings)\n",
    "meta_df = pd.DataFrame({\n",
    "    \"image_path\": valid_paths,\n",
    "    \"caption\": captions\n",
    "})\n",
    "final_df = pd.concat([meta_df, embedding_df], axis=1)\n",
    "\n",
    "final_df.to_csv(\"image_embeddings_clip.csv\", index=False)\n",
    "print(\"¡Embeddings generados y guardados en image_embeddings_clip.csv!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4aa27",
   "metadata": {},
   "source": [
    "Indexar con FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1ac3b",
   "metadata": {},
   "source": [
    "Texto e Imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "858c164a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices FAISS creados y guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Cargar embeddings de imágenes\n",
    "df_img = pd.read_csv(\"image_embeddings_clip.csv\")\n",
    "df_img.iloc[:, 2:] = df_img.iloc[:, 2:].apply(pd.to_numeric, errors=\"coerce\")\n",
    "image_embeddings = df_img.iloc[:, 2:].values.astype(\"float32\").copy()\n",
    "faiss.normalize_L2(image_embeddings)\n",
    "\n",
    "# Crear índice de imágenes\n",
    "image_index = faiss.IndexFlatIP(image_embeddings.shape[1])\n",
    "image_index.add(image_embeddings)\n",
    "faiss.write_index(image_index, \"faiss_image.index\")\n",
    "\n",
    "# Cargar embeddings de texto\n",
    "df_txt = pd.read_csv(\"text_embeddings_clip.csv\")\n",
    "df_txt.iloc[:, 2:] = df_txt.iloc[:, 2:].apply(pd.to_numeric, errors=\"coerce\")\n",
    "text_embeddings = df_txt.iloc[:, 2:].values.astype(\"float32\").copy()\n",
    "faiss.normalize_L2(text_embeddings)\n",
    "\n",
    "# Crear índice de textos\n",
    "text_index = faiss.IndexFlatIP(text_embeddings.shape[1])\n",
    "text_index.add(text_embeddings)\n",
    "faiss.write_index(text_index, \"faiss_text.index\")\n",
    "\n",
    "print(\"Índices FAISS creados y guardados correctamente.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659b2199",
   "metadata": {},
   "source": [
    "Busqueda Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657231f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "# Cargar modelo CLIP\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def search_text_to_image(query, top_k=5):\n",
    "    inputs = processor(text=[query], return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        query_embedding = model.get_text_features(**inputs).cpu().numpy().astype(\"float32\")\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    scores, indices = image_index.search(query_embedding, k=top_k * 10)\n",
    "\n",
    "    seen_images = set()\n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        image_path = df_img.iloc[idx]['image_path']\n",
    "        if image_path not in seen_images:\n",
    "            seen_images.add(image_path)\n",
    "            results.append({\n",
    "                \"image_path\": image_path,\n",
    "                \"caption\": df_img.iloc[idx]['caption'],\n",
    "                \"score\": score\n",
    "            })\n",
    "        if len(results) == top_k:  # Devuelve solo top_k imágenes únicas\n",
    "            break\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ca6de",
   "metadata": {},
   "source": [
    "Busqueda Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.get_image_features(**inputs)\n",
    "        embedding = embedding / embedding.norm(p=2, dim=-1, keepdim=True)\n",
    "    return embedding.cpu().numpy().astype(\"float32\")\n",
    "\n",
    "def search_image_to_image(query_image_path, top_k=5):\n",
    "    query_vec = get_image_embedding(query_image_path)\n",
    "    faiss.normalize_L2(query_vec)\n",
    "\n",
    "    # Buscar más para tener margen de deduplicación\n",
    "    D, I = image_index.search(query_vec, k=top_k * 10)\n",
    "\n",
    "    seen_paths = set()\n",
    "    results = []\n",
    "\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        item = df_img.iloc[idx]\n",
    "        img_path = item[\"image_path\"]\n",
    "\n",
    "        if img_path not in seen_paths and img_path != query_image_path:\n",
    "            seen_paths.add(img_path)\n",
    "            results.append({\n",
    "                \"image_path\": img_path,\n",
    "                \"caption\": item[\"caption\"],\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "        if len(results) >= top_kb:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "# =====================\n",
    "# Obtener Contexto\n",
    "# =====================\n",
    "def build_context_from_image_query(query_image_path, top_k=5):\n",
    "    resultados = search_image_to_image(query_image_path, top_k=top_k)\n",
    "    context = \"\"\n",
    "    for i, item in enumerate(resultados):\n",
    "        context += f\"[Imagen {i+1}]\\nRuta: {item['image_path']}\\nDescripción: {item['caption']}\\n\\n\"\n",
    "    return context.strip()\n",
    "\n",
    "def build_context_from_text_query(query, top_k=5):\n",
    "    resultados = search_text_to_image(query, top_k=top_k)\n",
    "    context = \"\"\n",
    "    for i, item in enumerate(resultados):\n",
    "        context += f\"[Imagen {i+1}]\\nRuta: {item['image_path']}\\nDescripción: {item['caption']}\\n\\n\"\n",
    "    return context.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ab7c3",
   "metadata": {},
   "source": [
    "Ejemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c62efd",
   "metadata": {},
   "source": [
    "TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08752626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Imagen: coco_dataset\\val2017\\000000255965.jpg - Caption: a stripped cat sitting near a brick wall - Score: 0.2787\n",
      "2. Imagen: coco_dataset\\val2017\\000000080666.jpg - Caption: A cat sitting on a bench in front of a building. - Score: 0.2776\n",
      "3. Imagen: coco_dataset\\val2017\\000000304560.jpg - Caption: A black cat is staring directly into the camera.  - Score: 0.2755\n",
      "4. Imagen: coco_dataset\\val2017\\000000014831.jpg - Caption: An up close photo of animals fur while laying on a blanket - Score: 0.2726\n",
      "5. Imagen: coco_dataset\\val2017\\000000118515.jpg - Caption: A small kitten sitting on a pallet of wood looking back. - Score: 0.2722\n",
      "\n",
      "Contexto generado:\n",
      "[Imagen 1]\n",
      "Ruta: coco_dataset\\val2017\\000000255965.jpg\n",
      "Descripción: a stripped cat sitting near a brick wall\n",
      "\n",
      "[Imagen 2]\n",
      "Ruta: coco_dataset\\val2017\\000000080666.jpg\n",
      "Descripción: A cat sitting on a bench in front of a building.\n",
      "\n",
      "[Imagen 3]\n",
      "Ruta: coco_dataset\\val2017\\000000304560.jpg\n",
      "Descripción: A black cat is staring directly into the camera. \n",
      "\n",
      "[Imagen 4]\n",
      "Ruta: coco_dataset\\val2017\\000000014831.jpg\n",
      "Descripción: An up close photo of animals fur while laying on a blanket\n",
      "\n",
      "[Imagen 5]\n",
      "Ruta: coco_dataset\\val2017\\000000118515.jpg\n",
      "Descripción: A small kitten sitting on a pallet of wood looking back.\n"
     ]
    }
   ],
   "source": [
    "query = \"a cat\"\n",
    "\n",
    "resultados = search_text_to_image(query, top_k=5)\n",
    "context = build_context_from_text_query(query, top_k=5)\n",
    "\n",
    "\n",
    "for i, item in enumerate(resultados):\n",
    "    print(f\"{i+1}. Imagen: {item['image_path']} - Caption: {item['caption']} - Score: {item['score']:.4f}\")\n",
    "print(\"\\nContexto generado:\")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc565b",
   "metadata": {},
   "source": [
    "IMAGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d72a7641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Imagen: coco_dataset\\val2017\\000000580197.jpg - Caption: Older man in tuxedo sitting next to another younger man in tuxedo. - Score: 0.9320\n",
      "2. Imagen: coco_dataset\\val2017\\000000032901.jpg - Caption: A group of four older men posing for a photo. - Score: 0.7042\n",
      "3. Imagen: coco_dataset\\val2017\\000000171190.jpg - Caption: A ground of people sitting around a table holding wine glasses in their hands. - Score: 0.6626\n",
      "4. Imagen: coco_dataset\\val2017\\000000391722.jpg - Caption: A man is being handed a birthday cake with lit candles. - Score: 0.6171\n",
      "5. Imagen: coco_dataset\\val2017\\000000271116.jpg - Caption: The men sit at a table with their phones in their hands. - Score: 0.5971\n",
      "\n",
      "Contexto generado:\n",
      "[Imagen 1]\n",
      "Ruta: coco_dataset\\val2017\\000000580197.jpg\n",
      "Descripción: Older man in tuxedo sitting next to another younger man in tuxedo.\n",
      "\n",
      "[Imagen 2]\n",
      "Ruta: coco_dataset\\val2017\\000000032901.jpg\n",
      "Descripción: A group of four older men posing for a photo.\n",
      "\n",
      "[Imagen 3]\n",
      "Ruta: coco_dataset\\val2017\\000000171190.jpg\n",
      "Descripción: A ground of people sitting around a table holding wine glasses in their hands.\n",
      "\n",
      "[Imagen 4]\n",
      "Ruta: coco_dataset\\val2017\\000000391722.jpg\n",
      "Descripción: A man is being handed a birthday cake with lit candles.\n",
      "\n",
      "[Imagen 5]\n",
      "Ruta: coco_dataset\\val2017\\000000271116.jpg\n",
      "Descripción: The men sit at a table with their phones in their hands.\n"
     ]
    }
   ],
   "source": [
    "query_img = \"coco_dataset/val2017/000000580197.jpg\"\n",
    "resultados = search_image_to_image(query_img, top_k=5)\n",
    "context = build_context_from_image_query(query_img, top_k=5)\n",
    "\n",
    "for i, res in enumerate(resultados):\n",
    "    print(f\"{i+1}. Imagen: {res['image_path']} - Caption: {res['caption']} - Score: {res['score']:.4f}\")\n",
    "print(\"\\nContexto generado:\")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9e77f",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ec0d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configurar tu clave\n",
    "genai.configure(api_key=\"AIzaSyA2DlSe8KtZvWmehFxjvZBuj-eL9IbTC2Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1c1ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gemini_response(context, prompt=\"Eres una aplicación de Retrieval Augmented Generation que siempre responde en español. Usa el siguiente contexto para responder la pregunta. Responde con una descripcion general usando todo tu contexto, evita dar exactamente tu contexto e ignora las rutas. Empieza siempre las imagenes que se muestran como resultado son...... Si la respuesta no está en el contexto, di que no sabes.\"):\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "    full_prompt = f\"{prompt}\\n\\nContexto:\\n{context}\"\n",
    "\n",
    "    response = model.generate_content(full_prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd2b805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las imagenes que se muestran como resultado son una colección de fotografías que representan a personas en diversas situaciones sociales y entornos. Se incluyen imágenes de hombres, algunos vistiendo esmoquin, tanto sentados en compañía de otros como posando en grupo. También hay escenas de personas reunidas alrededor de una mesa, en algunos casos con copas de vino o usando sus teléfonos, y una imagen de un hombre en el momento de recibir un pastel de cumpleaños.\n"
     ]
    }
   ],
   "source": [
    "respuesta = generate_gemini_response(context)\n",
    "print(respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INICIANDO SERVIDOR FASTAPI MULTIMODAL\n",
      "🚀 Iniciando servidor en puerto 8004...\n",
      "✅ Servidor iniciado correctamente en http://localhost:8004\n",
      "📖 Documentación API: http://localhost:8004/docs\n",
      "🖼️ Imágenes estáticas: http://localhost:8004/images/\n",
      "\n",
      "✅ TODAS LAS FUNCIONES ESTÁN DISPONIBLES\n",
      "\n",
      "🔍 Estado del sistema:\n",
      "   ✅ status: healthy\n",
      "   ✅ search_text_function: True\n",
      "   ✅ search_image_function: True\n",
      "   ✅ image_index: True\n",
      "   ✅ model_loaded: True\n",
      "   ✅ processor_loaded: True\n",
      "   ✅ df_img_loaded: True\n",
      "   ✅ context_functions: True\n",
      "   ✅ rag_function: True\n",
      "   ✅ index_size: 25014\n",
      "\n",
      "============================================================\n",
      "🎯 SERVIDOR FASTAPI LISTO\n",
      "   🌐 URL: http://localhost:8004\n",
      "   📱 Frontend: http://localhost:5173\n",
      "   🔧 Estado: Todas las funciones están disponibles\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Búsqueda por texto: 'a cat sitting'\n",
      "✅ Encontrados 10 resultados para 'a cat sitting'\n",
      "🔍 Búsqueda por texto: 'perros jugando'\n",
      "✅ Encontrados 10 resultados para 'perros jugando'\n",
      "🔍 Búsqueda por texto: 'carros'\n",
      "✅ Encontrados 10 resultados para 'carros'\n",
      "🔍 Búsqueda por texto: 'paisaje montañoso con lago'\n",
      "✅ Encontrados 10 resultados para 'paisaje montañoso con lago'\n",
      "🖼️ Búsqueda por imagen: car.jpg\n",
      "✅ Encontrados 10 resultados similares\n",
      "🖼️ Búsqueda por imagen: gatos.webp\n",
      "✅ Encontrados 10 resultados similares\n",
      "🖼️ Búsqueda por imagen: paisaje.jpg\n",
      "✅ Encontrados 10 resultados similares\n",
      "🔍 Búsqueda por texto: 'pene'\n",
      "✅ Encontrados 10 resultados para 'pene'\n",
      "🔍 Búsqueda por texto: 'culos'\n",
      "✅ Encontrados 10 resultados para 'culos'\n",
      "🔍 Búsqueda por texto: 'culo'\n",
      "✅ Encontrados 10 resultados para 'culo'\n",
      "🔍 Búsqueda por texto: 'trasero'\n",
      "✅ Encontrados 10 resultados para 'trasero'\n",
      "🔍 Búsqueda por texto: 'ass'\n",
      "⚠️ Error generando RAG: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 8.\n",
      "✅ Encontrados 10 resultados para 'ass'\n",
      "🔍 Búsqueda por texto: 'tren'\n",
      "✅ Encontrados 10 resultados para 'tren'\n",
      "🔍 Búsqueda por texto: 'origami'\n",
      "✅ Encontrados 10 resultados para 'origami'\n",
      "🔍 Búsqueda por texto: 'estadio de futbol'\n",
      "✅ Encontrados 10 resultados para 'estadio de futbol'\n",
      "🔍 Búsqueda por texto: 'insectos'\n",
      "✅ Encontrados 10 resultados para 'insectos'\n",
      "🔍 Búsqueda por texto: 'desayunos'\n",
      "✅ Encontrados 10 resultados para 'desayunos'\n",
      "🔍 Búsqueda por texto: 'gay'\n",
      "✅ Encontrados 10 resultados para 'gay'\n",
      "🔍 Búsqueda por texto: 'carro'\n",
      "✅ Encontrados 10 resultados para 'carro'\n",
      "🔍 Búsqueda por texto: 'gatos'\n",
      "✅ Encontrados 10 resultados para 'gatos'\n",
      "🖼️ Búsqueda por imagen: gatos.webp\n",
      "✅ Encontrados 10 resultados similares\n",
      "🖼️ Búsqueda por imagen: gatos.webp\n",
      "✅ Encontrados 10 resultados similares\n",
      "🖼️ Búsqueda por imagen: car.jpg\n",
      "✅ Encontrados 10 resultados similares\n",
      "🔍 Búsqueda por texto: 'cat'\n",
      "✅ Encontrados 10 resultados para 'cat'\n",
      "🔍 Búsqueda por texto: 'gato'\n",
      "✅ Encontrados 10 resultados para 'gato'\n",
      "🔍 Búsqueda por texto: 'ferchin'\n",
      "✅ Encontrados 10 resultados para 'ferchin'\n",
      "🔍 Búsqueda por texto: 'hola'\n",
      "✅ Encontrados 10 resultados para 'hola'\n",
      "🔍 Búsqueda por texto: 'gato'\n",
      "✅ Encontrados 10 resultados para 'gato'\n",
      "🔍 Búsqueda por texto: 'paisajes'\n",
      "✅ Encontrados 10 resultados para 'paisajes'\n",
      "🖼️ Búsqueda por imagen: gatos.webp\n",
      "✅ Encontrados 10 resultados similares\n",
      "🔍 Búsqueda por texto: 'gato negro'\n",
      "✅ Encontrados 10 resultados para 'gato negro'\n",
      "🔍 Búsqueda por texto: 'desayunos'\n",
      "✅ Encontrados 10 resultados para 'desayunos'\n",
      "🔍 Búsqueda por texto: 'almuerzo'\n",
      "✅ Encontrados 10 resultados para 'almuerzo'\n",
      "🔍 Búsqueda por texto: 'merienda'\n",
      "✅ Encontrados 10 resultados para 'merienda'\n",
      "🔍 Búsqueda por texto: 'Gatos'\n",
      "✅ Encontrados 10 resultados para 'Gatos'\n",
      "🖼️ Búsqueda por imagen: car.jpg\n",
      "✅ Encontrados 10 resultados similares\n",
      "🖼️ Búsqueda por imagen: sandwich.jpeg\n",
      "✅ Encontrados 10 resultados similares\n",
      "🖼️ Búsqueda por imagen: girasol.jpeg\n",
      "✅ Encontrados 10 resultados similares\n",
      "🔍 Búsqueda por texto: 'Girasol'\n",
      "✅ Encontrados 10 resultados para 'Girasol'\n",
      "🔍 Búsqueda por texto: 'gatos'\n",
      "✅ Encontrados 10 resultados para 'gatos'\n"
     ]
    }
   ],
   "source": [
    "# SERVIDOR FASTAPI PARA BÚSQUEDA MULTIMODAL\n",
    "import threading\n",
    "import time\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException, UploadFile, File, Form\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "\n",
    "print(\"🚀 INICIANDO SERVIDOR FASTAPI MULTIMODAL\")\n",
    "\n",
    "# Instalar dependencias si no están disponibles\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"google-generativeai\"])\n",
    "    import google.generativeai as genai\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"faiss-cpu\"])\n",
    "    import faiss\n",
    "\n",
    "# Configurar Gemini API\n",
    "genai.configure(api_key=\"AIzaSyA2DlSe8KtZvWmehFxjvZBuj-eL9IbTC2Y\")\n",
    "\n",
    "# Crear aplicación FastAPI\n",
    "app = FastAPI(title=\"Motor de Búsqueda Multimodal\", version=\"1.0.0\")\n",
    "\n",
    "# Configurar CORS para el frontend\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:5173\", \"http://127.0.0.1:5173\", \"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Montar archivos estáticos para servir imágenes\n",
    "if os.path.exists(\"coco_dataset/val2017\"):\n",
    "    app.mount(\"/images\", StaticFiles(directory=\"coco_dataset/val2017\"), name=\"images\")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"🚀 Motor de Búsqueda Multimodal v1.0.0\",\n",
    "        \"status\": \"active\",\n",
    "        \"endpoints\": [\"/health\", \"/search\", \"/search-by-image\"],\n",
    "        \"description\": \"Sistema de búsqueda multimodal con CLIP + FAISS + RAG\"\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    # Verificar que las funciones y variables estén disponibles\n",
    "    checks = {\n",
    "        \"status\": \"healthy\",\n",
    "        \"search_text_function\": 'search_text_to_image' in globals(),\n",
    "        \"search_image_function\": 'search_image_to_image' in globals(),\n",
    "        \"image_index\": 'image_index' in globals() and image_index is not None,\n",
    "        \"model_loaded\": 'model' in globals() and model is not None,\n",
    "        \"processor_loaded\": 'processor' in globals() and processor is not None,\n",
    "        \"df_img_loaded\": 'df_img' in globals(),\n",
    "        \"context_functions\": 'build_context_from_text_query' in globals(),\n",
    "        \"rag_function\": 'generate_gemini_response' in globals()\n",
    "    }\n",
    "    \n",
    "    if 'image_index' in globals() and image_index is not None:\n",
    "        checks[\"index_size\"] = image_index.ntotal\n",
    "    \n",
    "    return checks\n",
    "\n",
    "@app.post(\"/search\")\n",
    "async def search_text(request: dict):\n",
    "    \"\"\"Búsqueda por texto usando las funciones implementadas en el notebook\"\"\"\n",
    "    try:\n",
    "        query = request.get(\"query\", \"\").strip()\n",
    "        if not query:\n",
    "            raise HTTPException(status_code=400, detail=\"Query es requerido\")\n",
    "        \n",
    "        print(f\"🔍 Búsqueda por texto: '{query}'\")\n",
    "        \n",
    "        # Verificar que las funciones estén disponibles\n",
    "        if 'search_text_to_image' not in globals():\n",
    "            raise HTTPException(status_code=500, detail=\"Función search_text_to_image no está disponible. Ejecuta las celdas del notebook primero.\")\n",
    "        \n",
    "        # Realizar búsqueda usando la función del notebook\n",
    "        search_results = search_text_to_image(query, top_k=10)\n",
    "        \n",
    "        # Convertir resultados al formato esperado por el frontend\n",
    "        results = []\n",
    "        for i, result in enumerate(search_results):\n",
    "            filename = os.path.basename(result['image_path'])\n",
    "            similarity_percentage = max(0, min(100, float(result['score']) * 100))\n",
    "            \n",
    "            results.append({\n",
    "                \"id\": f\"img_{i}\",\n",
    "                \"type\": \"image\",\n",
    "                \"image_path\": result['image_path'],\n",
    "                \"image_url\": f\"http://localhost:8004/images/{filename}\",\n",
    "                \"text\": result['caption'],\n",
    "                \"score\": round(similarity_percentage, 1),\n",
    "                \"caption\": result['caption']\n",
    "            })\n",
    "        \n",
    "        # Generar respuesta RAG si las funciones están disponibles\n",
    "        rag_response = \"\"\n",
    "        if 'build_context_from_text_query' in globals() and 'generate_gemini_response' in globals():\n",
    "            try:\n",
    "                context = build_context_from_text_query(query, top_k=5)\n",
    "                rag_response = generate_gemini_response(context)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error generando RAG: {e}\")\n",
    "                rag_response = f\"Se encontraron {len(results)} imágenes relacionadas con '{query}'.\"\n",
    "        \n",
    "        print(f\"✅ Encontrados {len(results)} resultados para '{query}'\")\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"total_results\": len(results),\n",
    "            \"rag_response\": rag_response,\n",
    "            \"results\": results,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en búsqueda por texto: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise HTTPException(status_code=500, detail=f\"Error en búsqueda: {str(e)}\")\n",
    "\n",
    "@app.post(\"/search-by-image\")\n",
    "async def search_by_image(image: UploadFile = File(...)):\n",
    "    \"\"\"Búsqueda por imagen usando las funciones implementadas en el notebook\"\"\"\n",
    "    try:\n",
    "        if not image.content_type.startswith('image/'):\n",
    "            raise HTTPException(status_code=400, detail=\"El archivo debe ser una imagen\")\n",
    "        \n",
    "        print(f\"🖼️ Búsqueda por imagen: {image.filename}\")\n",
    "        \n",
    "        # Verificar que las funciones estén disponibles\n",
    "        if 'search_image_to_image' not in globals():\n",
    "            raise HTTPException(status_code=500, detail=\"Función search_image_to_image no está disponible. Ejecuta las celdas del notebook primero.\")\n",
    "        \n",
    "        # Leer y procesar la imagen subida\n",
    "        image_bytes = await image.read()\n",
    "        pil_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "        \n",
    "        # Guardar temporalmente la imagen\n",
    "        temp_path = f\"temp_upload_{image.filename}\"\n",
    "        pil_image.save(temp_path)\n",
    "        \n",
    "        try:\n",
    "            # Realizar búsqueda usando la función del notebook\n",
    "            search_results = search_image_to_image(temp_path, top_k=10)\n",
    "            \n",
    "            # Convertir resultados al formato esperado\n",
    "            results = []\n",
    "            for i, result in enumerate(search_results):\n",
    "                filename = os.path.basename(result['image_path'])\n",
    "                similarity_percentage = max(0, min(100, float(result['score']) * 100))\n",
    "                \n",
    "                results.append({\n",
    "                    \"id\": f\"img_{i}\",\n",
    "                    \"type\": \"image\",\n",
    "                    \"image_path\": result['image_path'],\n",
    "                    \"image_url\": f\"http://localhost:8004/images/{filename}\",\n",
    "                    \"text\": result['caption'],\n",
    "                    \"score\": round(similarity_percentage, 1),\n",
    "                    \"caption\": result['caption']\n",
    "                })\n",
    "            \n",
    "            # Generar respuesta RAG\n",
    "            rag_response = \"\"\n",
    "            if 'build_context_from_image_query' in globals() and 'generate_gemini_response' in globals():\n",
    "                try:\n",
    "                    context = build_context_from_image_query(temp_path, top_k=5)\n",
    "                    rag_response = generate_gemini_response(context)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error generando RAG: {e}\")\n",
    "                    rag_response = f\"Se encontraron {len(results)} imágenes similares a la imagen subida.\"\n",
    "            \n",
    "            print(f\"✅ Encontrados {len(results)} resultados similares\")\n",
    "            \n",
    "            return {\n",
    "                \"filename\": image.filename,\n",
    "                \"total_results\": len(results),\n",
    "                \"rag_response\": rag_response,\n",
    "                \"results\": results,\n",
    "                \"success\": True\n",
    "            }\n",
    "            \n",
    "        finally:\n",
    "            # Limpiar archivo temporal\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en búsqueda por imagen: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise HTTPException(status_code=500, detail=f\"Error en búsqueda por imagen: {str(e)}\")\n",
    "\n",
    "# Función para ejecutar el servidor\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8004, log_level=\"error\")\n",
    "\n",
    "def start_server():\n",
    "    print(\"🚀 Iniciando servidor en puerto 8004...\")\n",
    "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "    server_thread.start()\n",
    "    time.sleep(3)\n",
    "    return server_thread\n",
    "\n",
    "# Iniciar el servidor automáticamente\n",
    "try:\n",
    "    server_thread = start_server()\n",
    "    print(\"✅ Servidor iniciado correctamente en http://localhost:8004\")\n",
    "    print(\"📖 Documentación API: http://localhost:8004/docs\")\n",
    "    print(\"🖼️ Imágenes estáticas: http://localhost:8004/images/\")\n",
    "    print(\"\\n✅ TODAS LAS FUNCIONES ESTÁN DISPONIBLES\")\n",
    "    \n",
    "    # Verificación básica después de un momento\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8004/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            health = response.json()\n",
    "            print(\"\\n🔍 Estado del sistema:\")\n",
    "            for key, value in health.items():\n",
    "                status = \"✅\" if value else \"❌\"\n",
    "                print(f\"   {status} {key}: {value}\")\n",
    "        else:\n",
    "            print(\"⚠️ Error en verificación de salud del servidor\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error verificando servidor: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error iniciando servidor: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 SERVIDOR FASTAPI LISTO\")\n",
    "print(\"   🌐 URL: http://localhost:8004\")\n",
    "print(\"   📱 Frontend: http://localhost:5173\")\n",
    "print(\"   🔧 Estado: Todas las funciones están disponibles\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
